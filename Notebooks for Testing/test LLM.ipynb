{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = os.getenv('HUGGINGFACE_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ea6a5500924104ab4513ab468a792c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\", token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\", token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? I am so sorry that I didn’t post any recipes for a long time. I am very busy in my life. But I am very happy. I have my own blog now. It’s a very important step for me. I have a dream. I want to become a famous blogger. I hope I can do it. My dream is very big, but I have to do it. I am very excited. I hope you will enjoy my blog. Thank\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define a function to generate text\n",
    "def generate_text(prompt, max_length=100):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        prompt,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Move the input tensors to the GPU\n",
    "    inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "    inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a travel plan in Philadelphia for 2 days. I have a car and I want to see all the historical places. I am coming from New York.\n",
      "The Liberty Bell is a must see. The Constitution Center is a great place to learn about the Constitution. The National Constitution Center is the first museum in the United States dedicated to the U.S. Constitution and the story of We the People. The museum is located on the Delaware River in Historic Philadelphia, Pennsylvania. It is just a\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "prompt = \"Give me a travel plan in Philadelphia for 2 days\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
